# Summarise-meetings â€“ Transcription + Summarization with LLMs

Automatically transcribe and summarize your `.mp3` or `.wav` meeting recordings using open-source AI â€” **Whisper** + **LLaMA3** (via Ollama), wrapped in a simple **Streamlit app**.

---

## ðŸ“Œ Features

âœ… Upload `.mp3` or `.wav` audio files  
âœ… Transcription using `Whisper` (OpenAI speech-to-text model)  
âœ… Summarization using `llama3.2` (via Ollama, runs locally)  
âœ… Intuitive UI with Streamlit  
âœ… 100% local â€“ no API calls or data sharing

---

## ðŸ“Œ Demo


<img width="1439" alt="Image" src="https://github.com/user-attachments/assets/48e9eeca-e41f-426e-bff3-2a47a961dfff" />

<img width="1440" alt="Image" src="https://github.com/user-attachments/assets/18682d9d-7c09-4b9e-9bc3-44e4979be405" />

---

## ðŸ“Œ Tech Stack

- [Whisper](https://github.com/openai/whisper) for speech-to-text
- [Ollama](https://ollama.com) for running `llama3.2` locally
- [Streamlit](https://streamlit.io) for the web app
- Python + FFmpeg (for audio preprocessing)

---

## ðŸ“Œ Setup Instructions
You can run this project locally using **Anaconda** in terminal.

---

### 1. Clone the repo:

git clone https://github.com/jindsaini2013/Summarise-meetings.git

cd meeting-minute-generator 

### 2. Create and activate environment:

conda env create -f environment.yml

conda activate llms

### 3. Run the app:

streamlit run app.py

### 4. Additional Setup
Make sure FFmpeg is installed and accessible from your system PATH.
